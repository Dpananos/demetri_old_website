{
  "hash": "3bc67cb7fc5acaf68331a2042f2fe15f",
  "result": {
    "markdown": "---\ntitle: \"Log Link vs. Log(y)\"\nauthor: \"Demetri Pananos\"\ndate: \"2020-10-06\"\ncategories: [R, Statistics]\n---\n\n\n\nYou wanna see a little gotcha in statistics?  Take the following data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(0)\nN = 1000\ny = rlnorm(N, 0.5, 0.5)\n```\n:::\n\n\nand explain why `glm(y ~ 1, family = gaussian(link=log)` and  `lm(log(y)~1)` produce different estimates of the coefficients.  In case you don't have an R terminal, here are the outputs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_lm = lm(log(y) ~ 1)\nsummary(log_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = log(y) ~ 1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.61028 -0.34631 -0.02152  0.35173  1.64112 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.49209    0.01578   31.18   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.499 on 999 degrees of freedom\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_mod = glm(y ~ 1 , family = gaussian(link=log))\nsummary(glm_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = y ~ 1, family = gaussian(link = log))\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.5282  -0.6981  -0.2541   0.4702   6.5869  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.61791    0.01698    36.4   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.9918425)\n\n    Null deviance: 990.85  on 999  degrees of freedom\nResidual deviance: 990.85  on 999  degrees of freedom\nAIC: 2832.7\n\nNumber of Fisher Scoring iterations: 5\n```\n:::\n:::\n\n\nAnswer is the same as the difference between $E(g(X))$ and $g(E(X))$ which are not always the same.  Let me explain. \n\nFirst, let's start with the lognormal random variable.  $y \\sim \\operatorname{Lognormal}(\\mu, \\sigma)$ means $\\log(y) \\sim \\operatorname{Normal}(\\mu, \\sigma)$.  So $\\mu, \\sigma$ are the parameters of the underlying normal distribution.  When we do `lm(log(y) ~ 1)`, we are modelling $E(\\log(y)) = \\beta_0$.  So $\\beta_0$ is an estimate of $\\mu$ and $\\exp(\\mu)$ is an estimate of the median of the lognormal.  That is an easy check\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedian(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.600898\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Meh, close enough\nexp(coef(log_lm))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept) \n   1.635723 \n```\n:::\n:::\n\nIf I wanted an estimate of the mean of the lognormal, I would need to add $\\sigma^2/2$ to my estimate of $\\mu$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.855038\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Meh, close enough\nsigma = var(log_lm$residuals)\nexp(coef(log_lm) + sigma/2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept) \n   1.852594 \n```\n:::\n:::\n\n\nOk, onto the glm now.  When we use the glm, we model $\\log(E(y)) = \\beta_0$, so we model the mean of the lognormal directly.  Case in point\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.855038\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(coef(glm_mod))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept) \n   1.855038 \n```\n:::\n:::\n\n\n\nand if I wanted the median, I would need to consider the extra factor of $\\exp(\\sigma^2/2)$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedian(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.600898\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(coef(glm_mod) - sigma/2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept) \n   1.637881 \n```\n:::\n:::\n\n\nLog link vs. log outcome can be tricky.  Just be sure to know what you're modelling when you use either.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}